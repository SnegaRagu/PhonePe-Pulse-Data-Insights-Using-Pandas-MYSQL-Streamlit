{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4143b4d0-e10e-4d1b-8c16-673106e3ccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import mysql.connector as msql \n",
    "from mysql.connector import Error\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0569ba2-c6d5-49eb-bd3d-7e5fadb973ad",
   "metadata": {},
   "source": [
    "## DATA CLONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fef3d56d-a8a8-4893-8d26-895b76577893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clone():\n",
    "    repo_url = \"https://github.com/PhonePe/pulse.git\"\n",
    "\n",
    "    repo_name = os.path.basename(repo_url).removesuffix(\".git\")\n",
    "    clone_path = os.path.join(os.getcwd(),repo_name)\n",
    "\n",
    "    if not os.path.exists(clone_path):\n",
    "        Repo.clone_from(repo_url, clone_path)\n",
    "        print(f\"Data Cloned at {clone_path}\")\n",
    "    else:\n",
    "        print(f\"Data already cloned at {clone_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "835be29f-60a6-485c-9d57-98503e32bbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already cloned at C:\\Users\\snega\\OneDrive\\Desktop\\Data_Science\\Phonpe\\pulse\n"
     ]
    }
   ],
   "source": [
    "data_clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e05cf1-c029-43be-ae58-dc996c3c5492",
   "metadata": {},
   "source": [
    "## DATA EXTRACT AND TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5e9e7c8-f48d-4265-9a4c-0744e2697591",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_state_dir = []\n",
    "def rename_directories(path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        # Rename state directories according to geojson file\n",
    "        if os.path.basename(root) == 'state':\n",
    "            for state_name in dirs:\n",
    "                old_path =  os.path.join(root, state_name)\n",
    "                state_name.title().replace('-', ' ')\n",
    "                if state_name.startswith('Andaman'):\n",
    "                    state_name = 'Andaman & Nicobar'\n",
    "                elif state_name.startswith('Jammu'):\n",
    "                    state_name = 'Jammu & Kashmir'\n",
    "                elif state_name.startswith('Dadra'):\n",
    "                    state_name = 'Dadra and Nagar Haveli and Daman and Diu'  \n",
    "                new_path = os.path.join(root, state_name)\n",
    "                os.rename(old_path, new_path)\n",
    "                   \n",
    "        # To get all state basepath\n",
    "        if os.path.basename(root) == 'state' and root not in root_state_dir:\n",
    "            root_state_dir.append(root.replace('\\\\','/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d13be64b-0017-4a48-bd83-40c465998530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All State Directories renamed successfully. \n",
      "\n",
      "Base state directory paths:\n",
      "C:/Users/snega/OneDrive/Desktop/Data_Science/Phonpe/pulse/data/aggregated/insurance/country/india/state\n",
      "C:/Users/snega/OneDrive/Desktop/Data_Science/Phonpe/pulse/data/aggregated/transaction/country/india/state\n",
      "C:/Users/snega/OneDrive/Desktop/Data_Science/Phonpe/pulse/data/aggregated/user/country/india/state\n",
      "C:/Users/snega/OneDrive/Desktop/Data_Science/Phonpe/pulse/data/map/insurance/country/india/state\n",
      "C:/Users/snega/OneDrive/Desktop/Data_Science/Phonpe/pulse/data/map/insurance/hover/country/india/state\n",
      "C:/Users/snega/OneDrive/Desktop/Data_Science/Phonpe/pulse/data/map/transaction/hover/country/india/state\n",
      "C:/Users/snega/OneDrive/Desktop/Data_Science/Phonpe/pulse/data/map/user/hover/country/india/state\n",
      "C:/Users/snega/OneDrive/Desktop/Data_Science/Phonpe/pulse/data/top/insurance/country/india/state\n",
      "C:/Users/snega/OneDrive/Desktop/Data_Science/Phonpe/pulse/data/top/transaction/country/india/state\n",
      "C:/Users/snega/OneDrive/Desktop/Data_Science/Phonpe/pulse/data/top/user/country/india/state\n"
     ]
    }
   ],
   "source": [
    "rename_directories(os.getcwd())\n",
    "print(\"All State Directories renamed successfully. \\n\\nBase state directory paths:\")\n",
    "for root in root_state_dir:\n",
    "    print(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc693593-2034-4264-ad79-bfda8c961180",
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_extriform:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # Aggregated_user: Holds aggregated user-related data\n",
    "    def aggregated_user(self):\n",
    "        state_path = \"C:/Users/snega/OneDrive/Desktop/Data_Science/Phonpe/pulse/data/aggregated/user/country/india/state\"\n",
    "        state_list = os.listdir(state_path)\n",
    "        \n",
    "        aggr_user_dict = {\"State\" : [], \"Year\" : [], \"Quarter\" : [],\n",
    "                          \"Brand\" : [], \"User_Count\" : [], \"User_Percentage\" : []}\n",
    "        \n",
    "        for state in state_list:\n",
    "            year_path = os.path.join(state_path, state).replace('\\\\', '/')\n",
    "            year_list = os.listdir(year_path)\n",
    "\n",
    "            for year in year_list:\n",
    "                quarter_path = os.path.join(year_path, year).replace('\\\\', '/')\n",
    "                quarter_list = os.listdir(quarter_path)\n",
    "\n",
    "                for quarter in quarter_list:\n",
    "                    json_file_path = os.path.join(quarter_path, quarter).replace('\\\\', '/')\n",
    "                    f = open(json_file_path, \"r\")\n",
    "                    df = json.load(f)\n",
    "\n",
    "                    try:\n",
    "                        for user_data in df['data']['usersByDevice']:\n",
    "                            brand = user_data['brand']\n",
    "                            count = user_data['count']\n",
    "                            percent = user_data['percentage']\n",
    "                            \n",
    "                            # Append to aggr_user_dict\n",
    "                            aggr_user_dict[\"State\"].append(state)\n",
    "                            aggr_user_dict[\"Year\"].append(year)\n",
    "                            aggr_user_dict[\"Quarter\"].append('Q'+quarter[0])\n",
    "                            aggr_user_dict[\"Brand\"].append(brand)\n",
    "                            aggr_user_dict[\"User_Count\"].append(count)\n",
    "                            aggr_user_dict[\"User_Percentage\"].append(percent)\n",
    "                    except:\n",
    "                        pass\n",
    "        aggr_user_df = pd.DataFrame(aggr_user_dict)\n",
    "        aggr_user_df.to_csv(\"Pulse_Transformed/aggregated_user.csv\",index=False)\n",
    "        return aggr_user_df\n",
    "    \n",
    "    # Aggregated_transaction : Contains aggregated values for map-related data.\n",
    "    def aggregated_transaction(self):\n",
    "        state_path = \"C:/Users/snega/OneDrive/Desktop/Data_Science/Phonpe/pulse/data/aggregated/transaction/country/india/state\"\n",
    "        state_list = os.listdir(state_path)\n",
    "\n",
    "        aggr_trans_dict = {\"State\" : [], \"Year\" : [], \"Quarter\" : [],\n",
    "                           \"Transaction_Type\" : [], \"Transaction_Count\" : [], \"Transaction_Amount\" :[]}\n",
    "        \n",
    "        for state in state_list:\n",
    "            year_path = os.path.join(state_path, state).replace('\\\\', '/')\n",
    "            year_list = os.listdir(year_path)\n",
    "\n",
    "            for year in year_list:\n",
    "                quarter_path = os.path.join(year_path, year).replace('\\\\', '/')\n",
    "                quarter_list = os.listdir(quarter_path)\n",
    "\n",
    "                for quarter in quarter_list:\n",
    "                    json_file_path = os.path.join(quarter_path, quarter).replace('\\\\', '/')\n",
    "                    f = open(json_file_path, \"r\")\n",
    "                    df = json.load(f)\n",
    "\n",
    "                    try:\n",
    "                        for transaction_data in df['data']['transactionData']:\n",
    "                            name = transaction_data['name']\n",
    "                            count = transaction_data['paymentInstruments'][0]['count']\n",
    "                            amount = transaction_data['paymentInstruments'][0]['amount']\n",
    "                            \n",
    "                            # Append to aggr_trans_dict\n",
    "                            aggr_trans_dict[\"State\"].append(state)\n",
    "                            aggr_trans_dict[\"Year\"].append(year)\n",
    "                            aggr_trans_dict[\"Quarter\"].append('Q'+quarter[0])\n",
    "                            aggr_trans_dict[\"Transaction_Type\"].append(name)\n",
    "                            aggr_trans_dict[\"Transaction_Count\"].append(count)\n",
    "                            aggr_trans_dict[\"Transaction_Amount\"].append(amount)\n",
    "                    except:\n",
    "                        pass\n",
    "        aggr_trans_df = pd.DataFrame(aggr_trans_dict)\n",
    "        aggr_trans_df.to_csv(\"Pulse_Transformed/aggregated_transaction.csv\", index=False)\n",
    "        return aggr_trans_df\n",
    "\n",
    "    # Aggregated_insurance: Stores aggregated insurance-related data.\n",
    "    def aggregated_insurance(self):\n",
    "        state_path = \"C:/Users/snega/OneDrive/Desktop/Data_Science/Phonpe/pulse/data/aggregated/insurance/country/india/state\"\n",
    "        state_list = os.listdir(state_path)\n",
    "\n",
    "        aggr_ins_dict = {\"State\" : [], \"Year\" : [], \"Quarter\" : [],\n",
    "                         \"Type\" : [], \"Insurance_Count\" : [], \"Insurance_Amount\" : []}\n",
    "\n",
    "        for state in state_list:\n",
    "            year_path = os.path.join(state_path, state).replace('\\\\', '/')\n",
    "            year_list = os.listdir(year_path)\n",
    "\n",
    "            for year in year_list:\n",
    "                quarter_path = os.path.join(year_path, year).replace('\\\\', '/')\n",
    "                quarter_list = os.listdir(quarter_path)\n",
    "\n",
    "                for quarter in quarter_list:\n",
    "                    json_file_path = os.path.join(quarter_path, quarter).replace('\\\\', '/')\n",
    "                    f = open(json_file_path, \"r\")\n",
    "                    df = json.load(f)\n",
    "                    \n",
    "                    try:\n",
    "                        for ins_data in df['data']['transactionData']:\n",
    "                            types = ins_data['name']\n",
    "                            count = ins_data['paymentInstruments'][0]['count']\n",
    "                            amount = ins_data['paymentInstruments'][0]['amount']\n",
    "    \n",
    "                            # Append to aggr_ins_dict\n",
    "                            aggr_ins_dict[\"State\"].append(state)\n",
    "                            aggr_ins_dict[\"Year\"].append(year)\n",
    "                            aggr_ins_dict[\"Quarter\"].append('Q'+quarter[0])\n",
    "                            aggr_ins_dict[\"Type\"].append(types)\n",
    "                            aggr_ins_dict[\"Insurance_Count\"].append(count)\n",
    "                            aggr_ins_dict[\"Insurance_Amount\"].append(amount)\n",
    "                    except:\n",
    "                        pass\n",
    "        aggr_ins_df = pd.DataFrame(aggr_ins_dict)\n",
    "        aggr_ins_df.to_csv(\"Pulse_Transformed/aggregated_insurance.csv\", index=False)\n",
    "        return aggr_ins_df\n",
    "                    \n",
    "            \n",
    "    # Map_user: Contains mapping information for users.\n",
    "    def map_user(self):\n",
    "        state_path = \"C:/Users/snega/OneDrive/Desktop/Data_Science/Phonpe/pulse/data/map/user/hover/country/india/state\"\n",
    "        state_list = os.listdir(state_path)\n",
    "\n",
    "        map_user_dict = {\"State\" : [], \"Year\" : [], \"Quarter\" : [],\n",
    "                         \"District\" : [], \"Registered_Users\" : [], \"AppOpen_Count\" : []}\n",
    "        \n",
    "        for state in state_list:\n",
    "            year_path = os.path.join(state_path, state).replace('\\\\', '/')\n",
    "            year_list = os.listdir(year_path)\n",
    "\n",
    "            for year in year_list:\n",
    "                quarter_path = os.path.join(year_path, year).replace('\\\\', '/')\n",
    "                quarter_list = os.listdir(quarter_path)\n",
    "\n",
    "                for quarter in quarter_list:\n",
    "                    json_file_path = os.path.join(quarter_path, quarter).replace('\\\\', '/')\n",
    "                    f = open(json_file_path, \"r\")\n",
    "                    df = json.load(f)\n",
    "\n",
    "                    try:\n",
    "                        for district_key, user_data_value in df['data']['hoverData'].items():\n",
    "                            district = district_key.title().replace(' District', '')\n",
    "                            users = user_data_value['registeredUsers']\n",
    "                            app_count = user_data_value['appOpens']\n",
    "\n",
    "                            # Append to map_user_dict\n",
    "                            map_user_dict[\"State\"].append(state)\n",
    "                            map_user_dict[\"Year\"].append(year)\n",
    "                            map_user_dict[\"Quarter\"].append('Q'+quarter[0])\n",
    "                            map_user_dict[\"District\"].append(district)\n",
    "                            map_user_dict[\"Registered_Users\"].append(users)\n",
    "                            map_user_dict[\"AppOpen_Count\"].append(app_count)\n",
    "                    except:\n",
    "                        pass\n",
    "        map_user_df = pd.DataFrame(map_user_dict)\n",
    "        map_user_df.to_csv(\"Pulse_Transformed/map_user.csv\", index=False)\n",
    "        return map_user_df\n",
    "    \n",
    "    # Map_map: Holds mapping values for total amounts at state and district levels.\n",
    "    def map_transaction(self):\n",
    "        state_path = \"C:/Users/snega/OneDrive/Desktop/Data_Science/Phonpe/pulse/data/map/transaction/hover/country/india/state\"\n",
    "        state_list = os.listdir(state_path)\n",
    "\n",
    "        map_trans_dict = {\"State\" : [], \"Year\" : [], \"Quarter\" : [],\n",
    "                           \"District\" : [], \"Transaction_Count\" : [], \"Transaction_Amount\" : []}\n",
    "        \n",
    "        for state in state_list:\n",
    "            year_path = os.path.join(state_path, state).replace('\\\\', '/')\n",
    "            year_list = os.listdir(year_path)\n",
    "\n",
    "            for year in year_list:\n",
    "                quarter_path = os.path.join(year_path, year).replace('\\\\', '/')\n",
    "                quarter_list = os.listdir(quarter_path)\n",
    "\n",
    "                for quarter in quarter_list:\n",
    "                    json_file_path = os.path.join(quarter_path, quarter).replace('\\\\', '/')\n",
    "                    f = open(json_file_path, \"r\")\n",
    "                    df = json.load(f)\n",
    "\n",
    "                    try:\n",
    "                        for trans_value in df['data']['hoverDataList']:\n",
    "                            district = trans_value['name'].title().replace(' District', '')\n",
    "                            count = trans_value['metric'][0]['count']\n",
    "                            amount = trans_value['metric'][0]['amount']\n",
    "\n",
    "                            # Append to map_trans_dict\n",
    "                            map_trans_dict[\"State\"].append(state)\n",
    "                            map_trans_dict[\"Year\"].append(year)\n",
    "                            map_trans_dict[\"Quarter\"].append('Q'+quarter[0])\n",
    "                            map_trans_dict[\"District\"].append(district)\n",
    "                            map_trans_dict[\"Transaction_Count\"].append(count)\n",
    "                            map_trans_dict[\"Transaction_Amount\"].append(amount)\n",
    "                    except:\n",
    "                        pass\n",
    "        map_trans_df = pd.DataFrame(map_trans_dict)\n",
    "        map_trans_df.to_csv(\"Pulse_Transformed/map_transaction.csv\", index=False)\n",
    "        return map_trans_df\n",
    "\n",
    "\n",
    "    # Map_insurance: Includes mapping information related to insurance.\n",
    "    def map_insurance(self):\n",
    "        state_path = \"C:/Users/snega/OneDrive/Desktop/Data_Science/Phonpe/pulse/data/map/insurance/hover/country/india/state\"\n",
    "        state_list = os.listdir(state_path)\n",
    "\n",
    "        map_ins_dict = {\"State\" : [], \"Year\" : [], \"Quarter\" : [],\n",
    "                         \"District\" : [], \"Insurance_Count\" : [], \"Insurance_Amount\" : []}\n",
    "\n",
    "        for state in state_list:\n",
    "            year_path = os.path.join(state_path, state).replace('\\\\', '/')\n",
    "            year_list = os.listdir(year_path)\n",
    "\n",
    "            for year in year_list:\n",
    "                quarter_path = os.path.join(year_path, year).replace('\\\\', '/')\n",
    "                quarter_list = os.listdir(quarter_path)\n",
    "\n",
    "                for quarter in quarter_list:\n",
    "                    json_file_path = os.path.join(quarter_path, quarter).replace('\\\\', '/')\n",
    "                    df = pd.read_json(json_file_path)\n",
    "                    \n",
    "                    try:\n",
    "                        for ins_data in df['data']['hoverDataList']:\n",
    "                            district = ins_data['name'].title().replace(' District', '')\n",
    "                            count = ins_data['metric'][0]['count']\n",
    "                            amount = ins_data['metric'][0]['amount']\n",
    "    \n",
    "                            # Append to map_ins_dict\n",
    "                            map_ins_dict[\"State\"].append(state)\n",
    "                            map_ins_dict[\"Year\"].append(year)\n",
    "                            map_ins_dict[\"Quarter\"].append('Q'+quarter[0])\n",
    "                            map_ins_dict[\"District\"].append(district)\n",
    "                            map_ins_dict[\"Insurance_Count\"].append(count)\n",
    "                            map_ins_dict[\"Insurance_Amount\"].append(amount)\n",
    "                    except:\n",
    "                        pass\n",
    "        map_ins_df = pd.DataFrame(map_ins_dict)\n",
    "        map_ins_df.to_csv(\"Pulse_Transformed/map_insurance.csv\", index=False)\n",
    "        return map_ins_df\n",
    "\n",
    "    # Top_user: Lists totals for the top users.\n",
    "    def top_user_district(self):\n",
    "        state_path = \"pulse/data/top/user/country/india/state\"\n",
    "        state_list = os.listdir(state_path)\n",
    "\n",
    "        top_user_district_dict = {\"State\" : [], \"Year\" : [], \"Quarter\" : [],\n",
    "                         \"District\" : [], \"Registered_Users\" : []}\n",
    "        \n",
    "        for state in state_list:\n",
    "            year_path = os.path.join(state_path, state).replace('\\\\', '/')\n",
    "            year_list = os.listdir(year_path)\n",
    "\n",
    "            for year in year_list:\n",
    "                quarter_path = os.path.join(year_path, year).replace('\\\\', '/')\n",
    "                quarter_list = os.listdir(quarter_path)\n",
    "\n",
    "                for quarter in quarter_list:\n",
    "                    json_file_path = os.path.join(quarter_path, quarter).replace('\\\\', '/')\n",
    "                    df = pd.read_json(json_file_path)\n",
    "\n",
    "                    try:\n",
    "                        for top_users in df['data']['districts']:\n",
    "                            district = top_users['name'].title().replace(' District', '')\n",
    "                            count = top_users['registeredUsers']\n",
    "\n",
    "                            # Append to top_user_dict\n",
    "                            top_user_district_dict[\"State\"].append(state)\n",
    "                            top_user_district_dict[\"Year\"].append(year)\n",
    "                            top_user_district_dict[\"Quarter\"].append('Q'+quarter[0])\n",
    "                            top_user_district_dict[\"District\"].append(district)\n",
    "                            top_user_district_dict[\"Registered_Users\"].append(count)\n",
    "                    except:\n",
    "                        pass\n",
    "        top_user_district_df = pd.DataFrame(top_user_district_dict)\n",
    "        top_user_district_df.to_csv(\"Pulse_Transformed/top_user_district.csv\", index=False)\n",
    "        return top_user_district_df\n",
    "    \n",
    "    def top_user_pincode(self):\n",
    "        state_path = \"pulse/data/top/user/country/india/state\"\n",
    "        state_list = os.listdir(state_path)\n",
    "\n",
    "        top_user_pincode_dict = {\"State\" : [], \"Year\" : [], \"Quarter\" : [],\n",
    "                         \"Pincode\" : [], \"Registered_Users\" : []}\n",
    "        \n",
    "        for state in state_list:\n",
    "            year_path = os.path.join(state_path, state).replace('\\\\', '/')\n",
    "            year_list = os.listdir(year_path)\n",
    "\n",
    "            for year in year_list:\n",
    "                quarter_path = os.path.join(year_path, year).replace('\\\\', '/')\n",
    "                quarter_list = os.listdir(quarter_path)\n",
    "\n",
    "                for quarter in quarter_list:\n",
    "                    json_file_path = os.path.join(quarter_path, quarter).replace('\\\\', '/')\n",
    "                    df = pd.read_json(json_file_path)\n",
    "\n",
    "                    try:\n",
    "                        for top_users in df['data']['pincodes']:\n",
    "                            code = top_users['name']\n",
    "                            count = top_users['registeredUsers']\n",
    "\n",
    "                            # Append to top_user_pincode_dict\n",
    "                            top_user_pincode_dict[\"State\"].append(state)\n",
    "                            top_user_pincode_dict[\"Year\"].append(year)\n",
    "                            top_user_pincode_dict[\"Quarter\"].append('Q'+quarter[0])\n",
    "                            top_user_pincode_dict[\"Pincode\"].append(code)\n",
    "                            top_user_pincode_dict[\"Registered_Users\"].append(count)\n",
    "                    except:\n",
    "                        pass\n",
    "        top_user_pincode_df = pd.DataFrame(top_user_pincode_dict)\n",
    "        top_user_pincode_df.to_csv(\"Pulse_Transformed/top_user_pincode.csv\", index=False)\n",
    "        return top_user_pincode_df\n",
    "    \n",
    "    # Top_map: Contains totals for the top states, districts, and pin codes.\n",
    "    def top_transaction_district(self):\n",
    "        state_path = \"pulse/data/top/transaction/country/india/state\"\n",
    "        state_list = os.listdir(state_path)\n",
    "\n",
    "        top_transaction_district_dict = {\"State\" : [], \"Year\" : [], \"Quarter\" : [],\n",
    "                                        \"District\" : [], \"Transaction_Count\" : [], \"Transaction_Amount\" : []}\n",
    "        \n",
    "        for state in state_list:\n",
    "            year_path = os.path.join(state_path, state).replace('\\\\', '/')\n",
    "            year_list = os.listdir(year_path)\n",
    "\n",
    "            for year in year_list:\n",
    "                quarter_path = os.path.join(year_path, year).replace('\\\\', '/')\n",
    "                quarter_list = os.listdir(quarter_path)\n",
    "\n",
    "                for quarter in quarter_list:\n",
    "                    json_file_path = os.path.join(quarter_path, quarter).replace('\\\\', '/')\n",
    "                    df = pd.read_json(json_file_path) \n",
    "\n",
    "                    try:\n",
    "                        for top_trans in df['data']['districts']: \n",
    "                            district = top_trans['entityName'].title().replace(' District', '')\n",
    "                            count = top_trans['metric']['count']\n",
    "                            amount = top_trans['metric']['amount']\n",
    "\n",
    "                            # Append to top_trans_district_dict\n",
    "                            top_transaction_district_dict[\"State\"].append(state)\n",
    "                            top_transaction_district_dict[\"Year\"].append(year)\n",
    "                            top_transaction_district_dict[\"Quarter\"].append('Q'+quarter[0])\n",
    "                            top_transaction_district_dict[\"District\"].append(district)\n",
    "                            top_transaction_district_dict[\"Transaction_Count\"].append(count)\n",
    "                            top_transaction_district_dict[\"Transaction_Amount\"].append(amount)\n",
    "                    except:\n",
    "                        pass\n",
    "        top_transaction_district_df = pd.DataFrame(top_transaction_district_dict)\n",
    "        top_transaction_district_df.to_csv(\"Pulse_Transformed/top_transaction_district.csv\", index=False)\n",
    "        return top_transaction_district_df\n",
    "    \n",
    "    def top_transaction_pincode(self):\n",
    "        state_path = \"pulse/data/top/transaction/country/india/state\"\n",
    "        state_list = os.listdir(state_path)\n",
    "\n",
    "        top_transaction_pincode_dict = {\"State\" : [], \"Year\" : [], \"Quarter\" : [],\n",
    "                                        \"Pincode\" : [], \"Transaction_Count\" : [], \"Transaction_Amount\" : []}\n",
    "        \n",
    "        for state in state_list:\n",
    "            year_path = os.path.join(state_path, state).replace('\\\\', '/')\n",
    "            year_list = os.listdir(year_path)\n",
    "\n",
    "            for year in year_list:\n",
    "                quarter_path = os.path.join(year_path, year).replace('\\\\', '/')\n",
    "                quarter_list = os.listdir(quarter_path)\n",
    "\n",
    "                for quarter in quarter_list:\n",
    "                    json_file_path = os.path.join(quarter_path, quarter).replace('\\\\', '/')\n",
    "                    df = pd.read_json(json_file_path) \n",
    "\n",
    "                    try:\n",
    "                        for top_trans in df['data']['pincodes']: \n",
    "                            pincode = top_trans['entityName']\n",
    "                            count = top_trans['metric']['count']\n",
    "                            amount = top_trans['metric']['amount']\n",
    "\n",
    "                            # Append to top_trans_district_dict\n",
    "                            top_transaction_pincode_dict[\"State\"].append(state)\n",
    "                            top_transaction_pincode_dict[\"Year\"].append(year)\n",
    "                            top_transaction_pincode_dict[\"Quarter\"].append('Q'+quarter[0])\n",
    "                            top_transaction_pincode_dict[\"Pincode\"].append(pincode)\n",
    "                            top_transaction_pincode_dict[\"Transaction_Count\"].append(count)\n",
    "                            top_transaction_pincode_dict[\"Transaction_Amount\"].append(amount)\n",
    "                    except:\n",
    "                        pass\n",
    "        top_transaction_pincode_df = pd.DataFrame(top_transaction_pincode_dict)\n",
    "        top_transaction_pincode_df.to_csv(\"Pulse_Transformed/top_transaction_pincode.csv\", index=False)\n",
    "        return top_transaction_pincode_df\n",
    "\n",
    "    # Top_insurance: Lists totals for the top insurance categories\n",
    "    def top_insurance_district(self):\n",
    "        state_path = \"C:/Users/snega/OneDrive/Desktop/Data_Science/Phonpe/pulse/data/top/insurance/country/india/state\"\n",
    "        state_list = os.listdir(state_path)\n",
    "\n",
    "        top_insurance_district_dict = {\"State\" : [], \"Year\" : [], \"Quarter\" : [],\n",
    "                                        \"District\" : [], \"Insurance_Count\" : [], \"Insurance_Amount\" : []}\n",
    "        \n",
    "        for state in state_list:\n",
    "            year_path = os.path.join(state_path, state).replace('\\\\', '/')\n",
    "            year_list = os.listdir(year_path)\n",
    "\n",
    "            for year in year_list:\n",
    "                quarter_path = os.path.join(year_path, year).replace('\\\\', '/')\n",
    "                quarter_list = os.listdir(quarter_path)\n",
    "\n",
    "                for quarter in quarter_list:\n",
    "                    json_file_path = os.path.join(quarter_path, quarter).replace('\\\\', '/')\n",
    "                    df = pd.read_json(json_file_path) \n",
    "\n",
    "                    try:\n",
    "                        for top_ins in df['data']['districts']: \n",
    "                            district = top_ins['entityName'].title().replace(' District', '')\n",
    "                            count = top_ins['metric']['count']\n",
    "                            amount = top_ins['metric']['amount']\n",
    "\n",
    "                            # Append to top_trans_district_dict\n",
    "                            top_insurance_district_dict[\"State\"].append(state)\n",
    "                            top_insurance_district_dict[\"Year\"].append(year)\n",
    "                            top_insurance_district_dict[\"Quarter\"].append('Q'+quarter[0])\n",
    "                            top_insurance_district_dict[\"District\"].append(district)\n",
    "                            top_insurance_district_dict[\"Insurance_Count\"].append(count)\n",
    "                            top_insurance_district_dict[\"Insurance_Amount\"].append(amount)\n",
    "                    except:\n",
    "                        pass\n",
    "        top_insurance_district_df = pd.DataFrame(top_insurance_district_dict)\n",
    "        top_insurance_district_df.to_csv(\"Pulse_Transformed/top_insurance_district.csv\", index=False)\n",
    "        return top_insurance_district_df\n",
    "\n",
    "    def top_insurance_pincode(self):\n",
    "        state_path = \"C:/Users/snega/OneDrive/Desktop/Data_Science/Phonpe/pulse/data/top/insurance/country/india/state\"\n",
    "        state_list = os.listdir(state_path)\n",
    "\n",
    "        top_insurance_pincode_dict = {\"State\" : [], \"Year\" : [], \"Quarter\" : [],\n",
    "                                      \"Pincode\" : [], \"Insurance_Count\" : [], \"Insurance_Amount\" : []}\n",
    "        \n",
    "        for state in state_list:\n",
    "            year_path = os.path.join(state_path, state).replace('\\\\', '/')\n",
    "            year_list = os.listdir(year_path)\n",
    "\n",
    "            for year in year_list:\n",
    "                quarter_path = os.path.join(year_path, year).replace('\\\\', '/')\n",
    "                quarter_list = os.listdir(quarter_path)\n",
    "\n",
    "                for quarter in quarter_list:\n",
    "                    json_file_path = os.path.join(quarter_path, quarter).replace('\\\\', '/')\n",
    "                    df = pd.read_json(json_file_path) \n",
    "\n",
    "                    try:\n",
    "                        for top_ins in df['data']['pincodes']: \n",
    "                            pincode = top_ins['entityName']\n",
    "                            count = top_ins['metric']['count']\n",
    "                            amount = top_ins['metric']['amount']\n",
    "\n",
    "                            # Append to top_trans_district_dict\n",
    "                            top_insurance_pincode_dict[\"State\"].append(state)\n",
    "                            top_insurance_pincode_dict[\"Year\"].append(year)\n",
    "                            top_insurance_pincode_dict[\"Quarter\"].append('Q'+quarter[0])\n",
    "                            top_insurance_pincode_dict[\"Pincode\"].append(pincode)\n",
    "                            top_insurance_pincode_dict[\"Insurance_Count\"].append(count)\n",
    "                            top_insurance_pincode_dict[\"Insurance_Amount\"].append(amount)\n",
    "                    except:\n",
    "                        pass\n",
    "        top_insurance_pincode_df = pd.DataFrame(top_insurance_pincode_dict)\n",
    "        top_insurance_pincode_df.to_csv(\"Pulse_Transformed/top_insurance_pincode.csv\", index=False)\n",
    "        return top_insurance_pincode_df\n",
    "\n",
    "    # Latitude and Longitude Map\n",
    "    def lat_long_map_statelevel(self):\n",
    "        state_path = \"C:/Users/snega/OneDrive/Desktop/Data_Science/Phonpe/pulse/data/map/insurance/country/india/state\"\n",
    "        state_list = os.listdir(state_path)\n",
    "\n",
    "        lat_long_state_map_dict = {\"State\" : [], \"District\" : [], \"Latitude\" : [], \"Longitude\" : [], \"Metric\" : []}\n",
    "\n",
    "        for state in state_list:\n",
    "            year_path = os.path.join(state_path, state).replace('\\\\', '/')\n",
    "            year_list = os.listdir(year_path)\n",
    "            \n",
    "            for year in year_list:\n",
    "                quarter_path = os.path.join(year_path, year).replace('\\\\', '/')\n",
    "                quarter_list = os.listdir(quarter_path)\n",
    "\n",
    "                for quarter in quarter_list:\n",
    "                    json_file_path = os.path.join(quarter_path, quarter).replace('\\\\', '/')\n",
    "                    f = open(json_file_path, \"r\")\n",
    "                    df = json.load(f)\n",
    "\n",
    "                    try:\n",
    "                        for loc in df['data']['data']['data']:    # Reading via JSON\n",
    "                            lat, long, metric, label = loc\n",
    "\n",
    "                            # Append to lat_long_state_map_dict\n",
    "                            lat_long_state_map_dict[\"State\"].append(state)\n",
    "                            lat_long_state_map_dict[\"District\"].append(label.title().replace(' District', ''))\n",
    "                            lat_long_state_map_dict[\"Latitude\"].append(lat)\n",
    "                            lat_long_state_map_dict[\"Longitude\"].append(long)\n",
    "                            lat_long_state_map_dict[\"Metric\"].append(metric)\n",
    "                    except:\n",
    "                        pass\n",
    "        lat_long_state_map_df = pd.DataFrame(lat_long_state_map_dict)\n",
    "        lat_long_state_map_df.to_csv(\"Pulse_Transformed/lat_long_state_map.csv\", index=False)\n",
    "        return lat_long_state_map_df\n",
    "            \n",
    "    def lat_long_map_countrylevel(self):\n",
    "        country_path = \"C:/Users/snega/OneDrive/Desktop/Data_Science/Phonpe/pulse/data/map/insurance/country/india\"\n",
    "        year_list = os.listdir(country_path)\n",
    "     \n",
    "        lat_long_india_map_dict = {\"State\" : [], \"Latitude\" : [], \"Longitude\" : [], \"Metric\" : []}\n",
    "    \n",
    "        for year in year_list:\n",
    "            year_path = os.path.join(country_path, year).replace('\\\\', '/')\n",
    "            if os.path.basename(year_path) != \"state\":\n",
    "                quarter_list = os.listdir(year_path)\n",
    "    \n",
    "                for quarter in quarter_list:\n",
    "                    json_file_path = os.path.join(year_path, quarter).replace('\\\\', '/')\n",
    "                    f = open(json_file_path, \"r\")\n",
    "                    df = json.load(f)\n",
    "    \n",
    "                    try:\n",
    "                        for loc in df['data']['data']['data']:    # Reading via JSON\n",
    "                            lat, long, metric, label = loc\n",
    "                            \n",
    "                            # Append to lat_long_map_dict\n",
    "                            lat_long_india_map_dict[\"State\"].append(label.title().replace('-', ' ').replace('&', 'and'))\n",
    "                            lat_long_india_map_dict[\"Latitude\"].append(lat)\n",
    "                            lat_long_india_map_dict[\"Longitude\"].append(long)\n",
    "                            lat_long_india_map_dict[\"Metric\"].append(metric)\n",
    "                    except:\n",
    "                        pass\n",
    "    \n",
    "        lat_long_india_map_df = pd.DataFrame(lat_long_india_map_dict)\n",
    "        lat_long_india_map_df.to_csv(\"Pulse_Transformed/lat_long_india_map.csv\", index=False)\n",
    "        return lat_long_india_map_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcaee558-d33e-4377-9361-6816144a9b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Extract and Transform\n",
      "JSON to DataFrame and CSV Files converted successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Extract and Transform\")\n",
    "aggr_user_df = data_extriform().aggregated_user()\n",
    "aggr_trans_df = data_extriform().aggregated_transaction()\n",
    "aggr_ins_df = data_extriform().aggregated_insurance()\n",
    "map_user_df = data_extriform().map_user()\n",
    "map_trans_df = data_extriform().map_transaction()\n",
    "map_ins_df = data_extriform().map_insurance()\n",
    "top_user_districtwise_df = data_extriform().top_user_district()\n",
    "top_user_pincodewise_df = data_extriform().top_user_pincode()\n",
    "top_trans_districtwise_df = data_extriform().top_transaction_district()\n",
    "top_trans_pincodewise_df = data_extriform().top_transaction_pincode()\n",
    "top_ins_districtwise_df = data_extriform().top_insurance_district()\n",
    "top_ins_pincodewise_df = data_extriform().top_insurance_pincode()\n",
    "lat_long_state_df = data_extriform().lat_long_map_statelevel()\n",
    "lat_long_india_df = data_extriform().lat_long_map_countrylevel()\n",
    "print(\"JSON to DataFrame and CSV Files converted successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad3a44f-27fb-4f08-afa9-a348539d8fb0",
   "metadata": {},
   "source": [
    "## DATA LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "322190bc-fede-4149-9377-b92259ff8a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class load_database:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def sql_table_creation(self):\n",
    "        print(\"PHONEPE PULSE DB AND TABLE CREATION\")\n",
    "        try:\n",
    "            conn = msql.connect(host=\"localhost\", user=\"root\", password=\"root\", allow_local_infile=True)\n",
    "            cursor = conn.cursor()\n",
    "            print(\"* MYSQL Connection established\")\n",
    "\n",
    "            # DATABASE CREATION\n",
    "            cursor.execute(\"CREATE SCHEMA IF NOT EXISTS project_phonepe_pulse\")\n",
    "            cursor.execute(\"USE project_phonepe_pulse\")\n",
    "            print(\"* Selected phonpe DB\")\n",
    "\n",
    "            # TABLE CREATION\n",
    "\n",
    "            query = \"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS Aggregated_user(id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                                                                state VARCHAR(100),\n",
    "                                                                year INT,\n",
    "                                                                quarter VARCHAR(2),\n",
    "                                                                brand VARCHAR(100),\n",
    "                                                                user_count INT,\n",
    "                                                                user_percentage FLOAT);\n",
    "                    CREATE TABLE IF NOT EXISTS Aggregated_transaction(id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                                                                state VARCHAR(100),\n",
    "                                                                year INT,\n",
    "                                                                quarter VARCHAR(2),\n",
    "                                                                transaction_type VARCHAR(100),\n",
    "                                                                transaction_count INT UNSIGNED,\n",
    "                                                                transaction_amount FLOAT);\n",
    "                    CREATE TABLE IF NOT EXISTS Aggregated_insurance(id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                                                                state VARCHAR(100),\n",
    "                                                                year INT,\n",
    "                                                                quarter VARCHAR(2),\n",
    "                                                                type VARCHAR(100),\n",
    "                                                                insurance_count INT UNSIGNED,\n",
    "                                                                insurance_amount FLOAT);\n",
    "                    CREATE TABLE IF NOT EXISTS Map_user(id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                                                                state VARCHAR(100),\n",
    "                                                                year INT,\n",
    "                                                                quarter VARCHAR(2),\n",
    "                                                                district VARCHAR(100),\n",
    "                                                                registered_users INT,\n",
    "                                                                appopen_count INT);\n",
    "                    CREATE TABLE IF NOT EXISTS map_transaction(id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                                                                state VARCHAR(100),\n",
    "                                                                year INT,\n",
    "                                                                quarter VARCHAR(2),\n",
    "                                                                district VARCHAR(100),\n",
    "                                                                transaction_count INT,\n",
    "                                                                transaction_amount FLOAT);\n",
    "                    CREATE TABLE IF NOT EXISTS Map_insurance(id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                                                                state VARCHAR(100),\n",
    "                                                                year INT,\n",
    "                                                                quarter VARCHAR(2),\n",
    "                                                                district VARCHAR(100),\n",
    "                                                                insurance_count INT UNSIGNED,\n",
    "                                                                insurance_amount FLOAT);\n",
    "                    CREATE TABLE IF NOT EXISTS Top_user_districtwise(id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                                                                state VARCHAR(100),\n",
    "                                                                year INT,\n",
    "                                                                quarter VARCHAR(2),\n",
    "                                                                district VARCHAR(100),\n",
    "                                                                registered_users INT);\n",
    "                    CREATE TABLE IF NOT EXISTS Top_user_pincodewise(id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                                                                state VARCHAR(100),\n",
    "                                                                year INT,\n",
    "                                                                quarter VARCHAR(2),\n",
    "                                                                pincode VARCHAR(100),\n",
    "                                                                registered_users INT);\n",
    "                    CREATE TABLE IF NOT EXISTS Top_transaction_districtwise(id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                                                                state VARCHAR(100),\n",
    "                                                                year INT,\n",
    "                                                                quarter VARCHAR(2),\n",
    "                                                                district VARCHAR(100),\n",
    "                                                                transaction_count INT,\n",
    "                                                                transaction_amount FLOAT);\n",
    "                    CREATE TABLE IF NOT EXISTS Top_transaction_pincodewise(id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                                                                state VARCHAR(100),\n",
    "                                                                year INT,\n",
    "                                                                quarter VARCHAR(2),\n",
    "                                                                pincode VARCHAR(100),\n",
    "                                                                transaction_count INT,\n",
    "                                                                transaction_amount FLOAT);\n",
    "                    CREATE TABLE IF NOT EXISTS Top_insurance_districtwise(id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                                                                state VARCHAR(100),\n",
    "                                                                year INT,\n",
    "                                                                quarter VARCHAR(2),\n",
    "                                                                district VARCHAR(100),\n",
    "                                                                insurance_count INT,\n",
    "                                                                insurance_amount FLOAT);\n",
    "                    CREATE TABLE IF NOT EXISTS Top_insurance_pincodewise(id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                                                                state VARCHAR(100),\n",
    "                                                                year INT,\n",
    "                                                                quarter VARCHAR(2),\n",
    "                                                                pincode VARCHAR(100),\n",
    "                                                                insurance_count INT,\n",
    "                                                                insurance_amount FLOAT);\n",
    "                    CREATE TABLE IF NOT EXISTS State_level_location_metrics(id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                                                                state VARCHAR(100),\n",
    "                                                                district VARCHAR(100),\n",
    "                                                                latitude FLOAT,\n",
    "                                                                longitude FLOAT,\n",
    "                                                                metric FLOAT);\n",
    "                    CREATE TABLE IF NOT EXISTS India_level_location_metrics(id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                                                                state VARCHAR(100),\n",
    "                                                                latitude FLOAT,\n",
    "                                                                longitude FLOAT,\n",
    "                                                                metric FLOAT);\n",
    "                    \"\"\"\n",
    "            for _ in cursor.execute(query, multi=True):\n",
    "                pass\n",
    "            conn.commit()\n",
    "            print(\"* MYSQL phonepe_pulse database and table creation completed\")\n",
    "        except Error as e:\n",
    "            tb = sys.exc_info()\n",
    "            lineno = tb.tb_lineno\n",
    "            print(f\"* MYSQL DB & TABLE creation failed due to {e} at line number {lineno}\")\n",
    "        finally:\n",
    "            if cursor:\n",
    "                cursor.close()\n",
    "            if conn:\n",
    "                conn.close()\n",
    "\n",
    "    def data_transfer(self):\n",
    "        print(\"\\nDATA INSERTION TO SQL TABLE\")\n",
    "        try:\n",
    "            conn = msql.connect(host=\"localhost\", user=\"root\", password=\"root\", database=\"project_phonepe_pulse\")\n",
    "            print(\"* MYSQL Database Connection established\")\n",
    "\n",
    "            cursor = conn.cursor()\n",
    "\n",
    "            query = \"\"\"TRUNCATE TABLE Aggregated_user;\n",
    "                    TRUNCATE TABLE Aggregated_transaction;\n",
    "                    TRUNCATE TABLE Aggregated_insurance;\n",
    "                    TRUNCATE TABLE Map_user;\n",
    "                    TRUNCATE TABLE Map_transaction;\n",
    "                    TRUNCATE TABLE Map_insurance;\n",
    "                    TRUNCATE TABLE Top_user_districtwise;\n",
    "                    TRUNCATE TABLE Top_user_pincodewise;\n",
    "                    TRUNCATE TABLE Top_transaction_districtwise;\n",
    "                    TRUNCATE TABLE Top_transaction_pincodewise;\n",
    "                    TRUNCATE TABLE Top_insurance_districtwise;\n",
    "                    TRUNCATE TABLE Top_insurance_pincodewise;\n",
    "                    TRUNCATE TABLE State_level_location_metrics;\n",
    "                    TRUNCATE TABLE India_level_location_metrics\n",
    "                    \"\"\"\n",
    "            \n",
    "            for _ in cursor.execute(query, multi=True):\n",
    "                pass\n",
    "            conn.commit()\n",
    "            print(\"* Truncate tables completed\")\n",
    "\n",
    "            # Map Dataframe to SQL Table Name\n",
    "            map_df_dict = {\"Aggregated_user\" : aggr_user_df,\n",
    "                            \"Aggregated_transaction\" : aggr_trans_df,\n",
    "                            \"Aggregated_insurance\" : aggr_ins_df,\n",
    "                            \"Map_user\" : map_user_df,\n",
    "                            \"Map_transaction\" : map_trans_df,\n",
    "                            \"Map_insurance\" : map_ins_df,\n",
    "                            \"Top_user_districtwise\" : top_user_districtwise_df,\n",
    "                            \"Top_user_pincodewise\" : top_user_pincodewise_df,\n",
    "                            \"Top_transaction_districtwise\" : top_trans_districtwise_df,\n",
    "                            \"Top_transaction_pincodewise\" : top_trans_pincodewise_df,\n",
    "                            \"Top_insurance_districtwise\" : top_ins_districtwise_df,\n",
    "                            \"Top_insurance_pincodewise\" : top_ins_pincodewise_df,\n",
    "                            \"State_level_location_metrics\" : lat_long_state_df,\n",
    "                            \"India_level_location_metrics\" : lat_long_india_df\n",
    "                          }\n",
    "            \n",
    "            # Mapping Column Names to SQL Table Name\n",
    "            column_name_dict = {}\n",
    "\n",
    "            for table_name, data_f in map_df_dict.items():\n",
    "                column_name_dict[table_name] = tuple([col.lower() for col in data_f.columns.tolist()])\n",
    "        \n",
    "            for table_name in map_df_dict.keys():\n",
    "                curr_df = map_df_dict[table_name]\n",
    "                columns = column_name_dict[table_name]\n",
    "                val = \",\".join([\"%s\"] * len(columns))\n",
    "                query = f\"INSERT INTO {table_name} ({', '.join(columns)}) values ({val})\"\n",
    "                data = [tuple(row) for row in curr_df.to_numpy()]\n",
    "                print(f\"\\n  🚀 Inserting into table: {table_name}\")\n",
    "                print(f\"  Query: {query}\")\n",
    "                print(f\"  Sample row: {data[0]}\")\n",
    "                print(f\"  Expected: {len(columns)} values, Got: {len(data[0])} values\")\n",
    "                if table_name == \"State_level_location_metrics\" or table_name == \"India_level_location_metrics\":\n",
    "                    for i in range(0, len(data), 500):  # batches of 500\n",
    "                        batch = data[i:i+500]\n",
    "                        cursor.executemany(query, batch)\n",
    "                        conn.commit()\n",
    "                else:\n",
    "                    cursor.executemany(query, data)\n",
    "                    conn.commit()\n",
    "\n",
    "            conn.commit()\n",
    "            print(\"\\n* Table data migration completed\")\n",
    "        except Error as e:\n",
    "            import traceback, sys\n",
    "            exc_type, exc_value, tb = sys.exc_info()\n",
    "            lineno = tb.tb_lineno if tb else \"unknown\"\n",
    "            print(f\"* Table data insertion failed due to {e} at line number {lineno}\")\n",
    "        finally:\n",
    "            if cursor:\n",
    "                cursor.close()\n",
    "            if conn:\n",
    "                conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "093f106b-8b80-4003-8bf3-e636f4f3e426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHONEPE PULSE DB AND TABLE CREATION\n",
      "* MYSQL Connection established\n",
      "* Selected phonpe DB\n",
      "* MYSQL phonepe_pulse database and table creation completed\n",
      "\n",
      "DATA INSERTION TO SQL TABLE\n",
      "* MYSQL Database Connection established\n",
      "* Truncate tables completed\n",
      "\n",
      "  🚀 Inserting into table: Aggregated_user\n",
      "  Query: INSERT INTO Aggregated_user (state, year, quarter, brand, user_count, user_percentage) values (%s,%s,%s,%s,%s,%s)\n",
      "  Sample row: ('Andaman & Nicobar', '2018', 'Q1', 'Xiaomi', 1665, 0.2470326409495549)\n",
      "  Expected: 6 values, Got: 6 values\n",
      "\n",
      "  🚀 Inserting into table: Aggregated_transaction\n",
      "  Query: INSERT INTO Aggregated_transaction (state, year, quarter, transaction_type, transaction_count, transaction_amount) values (%s,%s,%s,%s,%s,%s)\n",
      "  Sample row: ('Andaman & Nicobar', '2018', 'Q1', 'Recharge & bill payments', 4200, 1845307.4673655091)\n",
      "  Expected: 6 values, Got: 6 values\n",
      "\n",
      "  🚀 Inserting into table: Aggregated_insurance\n",
      "  Query: INSERT INTO Aggregated_insurance (state, year, quarter, type, insurance_count, insurance_amount) values (%s,%s,%s,%s,%s,%s)\n",
      "  Sample row: ('Andaman & Nicobar', '2020', 'Q2', 'Insurance', 6, 1360.0)\n",
      "  Expected: 6 values, Got: 6 values\n",
      "\n",
      "  🚀 Inserting into table: Map_user\n",
      "  Query: INSERT INTO Map_user (state, year, quarter, district, registered_users, appopen_count) values (%s,%s,%s,%s,%s,%s)\n",
      "  Sample row: ('Andaman & Nicobar', '2018', 'Q1', 'North And Middle Andaman', 632, 0)\n",
      "  Expected: 6 values, Got: 6 values\n",
      "\n",
      "  🚀 Inserting into table: Map_transaction\n",
      "  Query: INSERT INTO Map_transaction (state, year, quarter, district, transaction_count, transaction_amount) values (%s,%s,%s,%s,%s,%s)\n",
      "  Sample row: ('Andaman & Nicobar', '2018', 'Q1', 'North And Middle Andaman', 442, 931663.0770939873)\n",
      "  Expected: 6 values, Got: 6 values\n",
      "\n",
      "  🚀 Inserting into table: Map_insurance\n",
      "  Query: INSERT INTO Map_insurance (state, year, quarter, district, insurance_count, insurance_amount) values (%s,%s,%s,%s,%s,%s)\n",
      "  Sample row: ('Andaman & Nicobar', '2020', 'Q2', 'South Andaman', 3, 795.0)\n",
      "  Expected: 6 values, Got: 6 values\n",
      "\n",
      "  🚀 Inserting into table: Top_user_districtwise\n",
      "  Query: INSERT INTO Top_user_districtwise (state, year, quarter, district, registered_users) values (%s,%s,%s,%s,%s)\n",
      "  Sample row: ('Andaman & Nicobar', '2018', 'Q1', 'South Andaman', 5846)\n",
      "  Expected: 5 values, Got: 5 values\n",
      "\n",
      "  🚀 Inserting into table: Top_user_pincodewise\n",
      "  Query: INSERT INTO Top_user_pincodewise (state, year, quarter, pincode, registered_users) values (%s,%s,%s,%s,%s)\n",
      "  Sample row: ('Andaman & Nicobar', '2018', 'Q1', '744103', 1608)\n",
      "  Expected: 5 values, Got: 5 values\n",
      "\n",
      "  🚀 Inserting into table: Top_transaction_districtwise\n",
      "  Query: INSERT INTO Top_transaction_districtwise (state, year, quarter, district, transaction_count, transaction_amount) values (%s,%s,%s,%s,%s,%s)\n",
      "  Sample row: ('Andaman & Nicobar', '2018', 'Q1', 'South Andaman', 5688, 12560249.34366581)\n",
      "  Expected: 6 values, Got: 6 values\n",
      "\n",
      "  🚀 Inserting into table: Top_transaction_pincodewise\n",
      "  Query: INSERT INTO Top_transaction_pincodewise (state, year, quarter, pincode, transaction_count, transaction_amount) values (%s,%s,%s,%s,%s,%s)\n",
      "  Sample row: ('Andaman & Nicobar', '2018', 'Q1', '744101', 1622, 2769297.9039997994)\n",
      "  Expected: 6 values, Got: 6 values\n",
      "\n",
      "  🚀 Inserting into table: Top_insurance_districtwise\n",
      "  Query: INSERT INTO Top_insurance_districtwise (state, year, quarter, district, insurance_count, insurance_amount) values (%s,%s,%s,%s,%s,%s)\n",
      "  Sample row: ('Andaman & Nicobar', '2020', 'Q2', 'Nicobars', 3, 565.0)\n",
      "  Expected: 6 values, Got: 6 values\n",
      "\n",
      "  🚀 Inserting into table: Top_insurance_pincodewise\n",
      "  Query: INSERT INTO Top_insurance_pincodewise (state, year, quarter, pincode, insurance_count, insurance_amount) values (%s,%s,%s,%s,%s,%s)\n",
      "  Sample row: ('Andaman & Nicobar', '2020', 'Q2', '744301', 3, 565.0)\n",
      "  Expected: 6 values, Got: 6 values\n",
      "\n",
      "  🚀 Inserting into table: State_level_location_metrics\n",
      "  Query: INSERT INTO State_level_location_metrics (state, district, latitude, longitude, metric) values (%s,%s,%s,%s,%s)\n",
      "  Sample row: ('Andaman & Nicobar', 'Nicobars', 9.173490186987454, 92.81284629716966, 3.0)\n",
      "  Expected: 5 values, Got: 5 values\n",
      "\n",
      "  🚀 Inserting into table: India_level_location_metrics\n",
      "  Query: INSERT INTO India_level_location_metrics (state, latitude, longitude, metric) values (%s,%s,%s,%s)\n",
      "  Sample row: ('Karnataka', 12.88117483333963, 77.56767350389504, 4720.0)\n",
      "  Expected: 4 values, Got: 4 values\n",
      "\n",
      "* Table data migration completed\n"
     ]
    }
   ],
   "source": [
    "load_database().sql_table_creation()\n",
    "load_database().data_transfer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf3c648-aa06-42a6-985f-fd43f21bb01e",
   "metadata": {},
   "source": [
    "## DATAFRAME INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f393d47-356e-4f42-8ec1-2748abe3e016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created DataFrame List:\n",
      " aggr_user_df\n",
      " aggr_trans_df\n",
      " aggr_ins_df\n",
      " map_user_df\n",
      " map_trans_df\n",
      " map_ins_df\n",
      " top_user_districtwise_df\n",
      " top_user_pincodewise_df\n",
      " top_trans_districtwise_df\n",
      " top_trans_pincodewise_df\n",
      " top_ins_districtwise_df\n",
      " top_ins_pincodewise_df\n",
      " lat_long_state_df\n",
      " lat_long_india_df\n"
     ]
    }
   ],
   "source": [
    "df_list = [key for key, val in globals().items() if isinstance(val, pd.DataFrame) and key.endswith('_df')]\n",
    "print(\"Created DataFrame List:\")\n",
    "for dfs in df_list:\n",
    "    print(f\" {dfs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab701b6f-7838-410a-a310-64f520b85be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Info:\n",
      " aggr_user_df info : \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6732 entries, 0 to 6731\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   State            6732 non-null   object \n",
      " 1   Year             6732 non-null   object \n",
      " 2   Quarter          6732 non-null   object \n",
      " 3   Brand            6732 non-null   object \n",
      " 4   User_Count       6732 non-null   int64  \n",
      " 5   User_Percentage  6732 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 315.7+ KB\n",
      "\n",
      " aggr_trans_df info : \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5034 entries, 0 to 5033\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   State               5034 non-null   object \n",
      " 1   Year                5034 non-null   object \n",
      " 2   Quarter             5034 non-null   object \n",
      " 3   Transaction_Type    5034 non-null   object \n",
      " 4   Transaction_Count   5034 non-null   int64  \n",
      " 5   Transaction_Amount  5034 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 236.1+ KB\n",
      "\n",
      " aggr_ins_df info : \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 682 entries, 0 to 681\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   State             682 non-null    object \n",
      " 1   Year              682 non-null    object \n",
      " 2   Quarter           682 non-null    object \n",
      " 3   Type              682 non-null    object \n",
      " 4   Insurance_Count   682 non-null    int64  \n",
      " 5   Insurance_Amount  682 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 32.1+ KB\n",
      "\n",
      " map_user_df info : \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20608 entries, 0 to 20607\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   State             20608 non-null  object\n",
      " 1   Year              20608 non-null  object\n",
      " 2   Quarter           20608 non-null  object\n",
      " 3   District          20608 non-null  object\n",
      " 4   Registered_Users  20608 non-null  int64 \n",
      " 5   AppOpen_Count     20608 non-null  int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 966.1+ KB\n",
      "\n",
      " map_trans_df info : \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20604 entries, 0 to 20603\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   State               20604 non-null  object \n",
      " 1   Year                20604 non-null  object \n",
      " 2   Quarter             20604 non-null  object \n",
      " 3   District            20604 non-null  object \n",
      " 4   Transaction_Count   20604 non-null  int64  \n",
      " 5   Transaction_Amount  20604 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 965.9+ KB\n",
      "\n",
      " map_ins_df info : \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13876 entries, 0 to 13875\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   State             13876 non-null  object \n",
      " 1   Year              13876 non-null  object \n",
      " 2   Quarter           13876 non-null  object \n",
      " 3   District          13876 non-null  object \n",
      " 4   Insurance_Count   13876 non-null  int64  \n",
      " 5   Insurance_Amount  13876 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 650.6+ KB\n",
      "\n",
      " top_user_districtwise_df info : \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8296 entries, 0 to 8295\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   State             8296 non-null   object\n",
      " 1   Year              8296 non-null   object\n",
      " 2   Quarter           8296 non-null   object\n",
      " 3   District          8296 non-null   object\n",
      " 4   Registered_Users  8296 non-null   int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 324.2+ KB\n",
      "\n",
      " top_user_pincodewise_df info : \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   State             10000 non-null  object\n",
      " 1   Year              10000 non-null  object\n",
      " 2   Quarter           10000 non-null  object\n",
      " 3   Pincode           10000 non-null  object\n",
      " 4   Registered_Users  10000 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 390.8+ KB\n",
      "\n",
      " top_trans_districtwise_df info : \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8296 entries, 0 to 8295\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   State               8296 non-null   object \n",
      " 1   Year                8296 non-null   object \n",
      " 2   Quarter             8296 non-null   object \n",
      " 3   District            8296 non-null   object \n",
      " 4   Transaction_Count   8296 non-null   int64  \n",
      " 5   Transaction_Amount  8296 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 389.0+ KB\n",
      "\n",
      " top_trans_pincodewise_df info : \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9999 entries, 0 to 9998\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   State               9999 non-null   object \n",
      " 1   Year                9999 non-null   object \n",
      " 2   Quarter             9999 non-null   object \n",
      " 3   Pincode             9997 non-null   object \n",
      " 4   Transaction_Count   9999 non-null   int64  \n",
      " 5   Transaction_Amount  9999 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 468.8+ KB\n",
      "\n",
      " top_ins_districtwise_df info : \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5608 entries, 0 to 5607\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   State             5608 non-null   object \n",
      " 1   Year              5608 non-null   object \n",
      " 2   Quarter           5608 non-null   object \n",
      " 3   District          5608 non-null   object \n",
      " 4   Insurance_Count   5608 non-null   int64  \n",
      " 5   Insurance_Amount  5608 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 263.0+ KB\n",
      "\n",
      " top_ins_pincodewise_df info : \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6668 entries, 0 to 6667\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   State             6668 non-null   object \n",
      " 1   Year              6668 non-null   object \n",
      " 2   Quarter           6668 non-null   object \n",
      " 3   Pincode           6665 non-null   object \n",
      " 4   Insurance_Count   6668 non-null   int64  \n",
      " 5   Insurance_Amount  6668 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 312.7+ KB\n",
      "\n",
      " lat_long_state_df info : \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1043137 entries, 0 to 1043136\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count    Dtype  \n",
      "---  ------     --------------    -----  \n",
      " 0   State      1043137 non-null  object \n",
      " 1   District   1043137 non-null  object \n",
      " 2   Latitude   1043137 non-null  float64\n",
      " 3   Longitude  1043137 non-null  float64\n",
      " 4   Metric     1043137 non-null  float64\n",
      "dtypes: float64(3), object(2)\n",
      "memory usage: 39.8+ MB\n",
      "\n",
      " lat_long_india_df info : \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 346856 entries, 0 to 346855\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   State      346856 non-null  object \n",
      " 1   Latitude   346856 non-null  float64\n",
      " 2   Longitude  346856 non-null  float64\n",
      " 3   Metric     346856 non-null  float64\n",
      "dtypes: float64(3), object(1)\n",
      "memory usage: 10.6+ MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"DataFrame Info:\")\n",
    "for dfs in df_list:\n",
    "    # get the actual DataFrame using its name\n",
    "    df = globals()[dfs]\n",
    "    print(f\" {dfs} info : \\n\")\n",
    "    df.info()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f399f6fd-1884-4f99-822a-9dc33c484c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated values\n",
      " Duplicates in aggr_user_df : 0\n",
      " Duplicates in aggr_trans_df : 0\n",
      " Duplicates in aggr_ins_df : 0\n",
      " Duplicates in map_user_df : 0\n",
      " Duplicates in map_trans_df : 0\n",
      " Duplicates in map_ins_df : 0\n",
      " Duplicates in top_user_districtwise_df : 0\n",
      " Duplicates in top_user_pincodewise_df : 0\n",
      " Duplicates in top_trans_districtwise_df : 0\n",
      " Duplicates in top_trans_pincodewise_df : 0\n",
      " Duplicates in top_ins_districtwise_df : 0\n",
      " Duplicates in top_ins_pincodewise_df : 0\n",
      " Duplicates in lat_long_state_df : 172281\n",
      " Duplicates in lat_long_india_df : 19682\n"
     ]
    }
   ],
   "source": [
    "print(\"Duplicated values\")\n",
    "for dfs in df_list:\n",
    "    df = globals()[dfs]\n",
    "    print(f\" Duplicates in {dfs} : {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9970fb8c-44bc-4bf0-9630-c5975e86ba4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NULL Value Count : \n",
      " NULL Values in aggr_user_df : \n",
      "State              0\n",
      "Year               0\n",
      "Quarter            0\n",
      "Brand              0\n",
      "User_Count         0\n",
      "User_Percentage    0\n",
      "dtype: int64\n",
      " NULL Values in aggr_trans_df : \n",
      "State                 0\n",
      "Year                  0\n",
      "Quarter               0\n",
      "Transaction_Type      0\n",
      "Transaction_Count     0\n",
      "Transaction_Amount    0\n",
      "dtype: int64\n",
      " NULL Values in aggr_ins_df : \n",
      "State               0\n",
      "Year                0\n",
      "Quarter             0\n",
      "Type                0\n",
      "Insurance_Count     0\n",
      "Insurance_Amount    0\n",
      "dtype: int64\n",
      " NULL Values in map_user_df : \n",
      "State               0\n",
      "Year                0\n",
      "Quarter             0\n",
      "District            0\n",
      "Registered_Users    0\n",
      "AppOpen_Count       0\n",
      "dtype: int64\n",
      " NULL Values in map_trans_df : \n",
      "State                 0\n",
      "Year                  0\n",
      "Quarter               0\n",
      "District              0\n",
      "Transaction_Count     0\n",
      "Transaction_Amount    0\n",
      "dtype: int64\n",
      " NULL Values in map_ins_df : \n",
      "State               0\n",
      "Year                0\n",
      "Quarter             0\n",
      "District            0\n",
      "Insurance_Count     0\n",
      "Insurance_Amount    0\n",
      "dtype: int64\n",
      " NULL Values in top_user_districtwise_df : \n",
      "State               0\n",
      "Year                0\n",
      "Quarter             0\n",
      "District            0\n",
      "Registered_Users    0\n",
      "dtype: int64\n",
      " NULL Values in top_user_pincodewise_df : \n",
      "State               0\n",
      "Year                0\n",
      "Quarter             0\n",
      "Pincode             0\n",
      "Registered_Users    0\n",
      "dtype: int64\n",
      " NULL Values in top_trans_districtwise_df : \n",
      "State                 0\n",
      "Year                  0\n",
      "Quarter               0\n",
      "District              0\n",
      "Transaction_Count     0\n",
      "Transaction_Amount    0\n",
      "dtype: int64\n",
      " NULL Values in top_trans_pincodewise_df : \n",
      "State                 0\n",
      "Year                  0\n",
      "Quarter               0\n",
      "Pincode               2\n",
      "Transaction_Count     0\n",
      "Transaction_Amount    0\n",
      "dtype: int64\n",
      " NULL Values in top_ins_districtwise_df : \n",
      "State               0\n",
      "Year                0\n",
      "Quarter             0\n",
      "District            0\n",
      "Insurance_Count     0\n",
      "Insurance_Amount    0\n",
      "dtype: int64\n",
      " NULL Values in top_ins_pincodewise_df : \n",
      "State               0\n",
      "Year                0\n",
      "Quarter             0\n",
      "Pincode             3\n",
      "Insurance_Count     0\n",
      "Insurance_Amount    0\n",
      "dtype: int64\n",
      " NULL Values in lat_long_state_df : \n",
      "State        0\n",
      "District     0\n",
      "Latitude     0\n",
      "Longitude    0\n",
      "Metric       0\n",
      "dtype: int64\n",
      " NULL Values in lat_long_india_df : \n",
      "State        0\n",
      "Latitude     0\n",
      "Longitude    0\n",
      "Metric       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"NULL Value Count : \")\n",
    "for dfs in df_list:\n",
    "    df = globals()[dfs]\n",
    "    print(f\" NULL Values in {dfs} : \\n{df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "361cc78c-43cf-4a26-9b58-fc38e8b7ff84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of dataframe:\n",
      " **aggr_user_df columns** : ['State', 'Year', 'Quarter', 'Brand', 'User_Count', 'User_Percentage']\n",
      " **aggr_trans_df columns** : ['State', 'Year', 'Quarter', 'Transaction_Type', 'Transaction_Count', 'Transaction_Amount']\n",
      " **aggr_ins_df columns** : ['State', 'Year', 'Quarter', 'Type', 'Insurance_Count', 'Insurance_Amount']\n",
      " **map_user_df columns** : ['State', 'Year', 'Quarter', 'District', 'Registered_Users', 'AppOpen_Count']\n",
      " **map_trans_df columns** : ['State', 'Year', 'Quarter', 'District', 'Transaction_Count', 'Transaction_Amount']\n",
      " **map_ins_df columns** : ['State', 'Year', 'Quarter', 'District', 'Insurance_Count', 'Insurance_Amount']\n",
      " **top_user_districtwise_df columns** : ['State', 'Year', 'Quarter', 'District', 'Registered_Users']\n",
      " **top_user_pincodewise_df columns** : ['State', 'Year', 'Quarter', 'Pincode', 'Registered_Users']\n",
      " **top_trans_districtwise_df columns** : ['State', 'Year', 'Quarter', 'District', 'Transaction_Count', 'Transaction_Amount']\n",
      " **top_trans_pincodewise_df columns** : ['State', 'Year', 'Quarter', 'Pincode', 'Transaction_Count', 'Transaction_Amount']\n",
      " **top_ins_districtwise_df columns** : ['State', 'Year', 'Quarter', 'District', 'Insurance_Count', 'Insurance_Amount']\n",
      " **top_ins_pincodewise_df columns** : ['State', 'Year', 'Quarter', 'Pincode', 'Insurance_Count', 'Insurance_Amount']\n",
      " **lat_long_state_df columns** : ['State', 'District', 'Latitude', 'Longitude', 'Metric']\n",
      " **lat_long_india_df columns** : ['State', 'Latitude', 'Longitude', 'Metric']\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns of dataframe:\")\n",
    "for dfs in df_list:\n",
    "    df = globals()[dfs]\n",
    "    print(f\" **{dfs} columns** : {df.columns.tolist()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
